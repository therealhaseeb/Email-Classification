{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeppavlov-bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvjorycYubo1QmdjeRABXu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therealhaseeb/Email-Classification/blob/main/deeppavlov_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqAE4rGP-Ao3"
      },
      "source": [
        "# 1) QA_System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6YOi-b66tIO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67ab2e08-4db3-4744-d22c-8683439d1e73"
      },
      "source": [
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install squad_zh_bert_zh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/87/e77ccc7de09f8c5c4a3d981ff6b1d3811d9978976a30bec9bdf50d667ebb/deeppavlov-0.15.0-py3-none-any.whl (907kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n",
            "Collecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
            "Collecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/5f/2bc87272f189662e129ddcd4807ad3ef83128b4df3a3482335f5f9790f24/uvicorn-0.11.7-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.6MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/fc/12de89822adaa3a60b8cb0139bae75918278999d08e6dff158623abd7cba/ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 34.1MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/53/127cb49435bcf5d841baf8eafa030931c62a9eac577a641f8c2293d23371/numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
            "Collecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/58/2deb24de3c10cc4c0f09639b46f4f4b50059f0fdc785128a57dd9fdce026/Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 28.0MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 31.4MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 14.4MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/56/1f652c3f658d2a9fd495d2e988a2da57eabdb6c4b8f4563c2ccbe6a2a8c5/pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 25.7MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting uvloop==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/7a/54a80c03b555af21680a2f3692947b43a0d576d90c4c18cace0fee1ccc0e/uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.4MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 40.0MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyopenssl==19.1.0->deeppavlov) (1.15.0)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 27.5MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/c4/dc5b9d50c15af2ee187974a5a0c3f20c06cce6559eea4c065d372e846b6a/aiormq-3.3.1-py3-none-any.whl\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2021.5.30)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 36.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/2e/485131e3aa113929b425f83854fafc190aa7df716cbeb258c875752f0c6e/httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 48.0MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.4MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2->deeppavlov) (1.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.5)\n",
            "Collecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 35.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: prometheus-client, overrides, sacremoses, pytelegrambotapi, nltk, starlette\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41404 sha256=6ffdbdef174f0b999dfbc246d3af1b57cfec0d23fd860568e369fd4a0d415fe9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp37-none-any.whl size=5606 sha256=493bcf29a1320292666826c5bda0a3248a59ccd7870600fb11a056e43ee6c286\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp37-none-any.whl size=883990 sha256=1f56e8484c3f1fc51bc5bd076309677ff08343170d22f806af9c9d0c6d0cd3d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp37-none-any.whl size=47177 sha256=28b5f1a6302f0fc31e9ead604f75a3da0f617457ece0f4eeb3ffc182d519e15f\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449925 sha256=a0f6d3ca06cc4f9074f0e62e450ba51dc317ffe7fbc3791de78c27b83f467f8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp37-none-any.whl size=57254 sha256=79adf05de25b1b5875ca2574f58e0a45c06a7d49221433458eaf55dd97a70dee\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built prometheus-client overrides sacremoses pytelegrambotapi nltk starlette\n",
            "\u001b[31mERROR: xarray 0.18.2 has requirement pandas>=1.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cryptography, pyopenssl, pamqp, idna, multidict, yarl, aiormq, aio-pika, requests, numpy, pytz, pandas, pymorphy2-dicts, dawg-python, pymorphy2, starlette, pydantic, fastapi, httptools, websockets, uvloop, h11, uvicorn, ruamel.yaml, prometheus-client, rusenttokenize, overrides, Cython, h5py, pymorphy2-dicts-ru, scikit-learn, sacremoses, pytelegrambotapi, nltk, deeppavlov\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: prometheus-client 0.11.0\n",
            "    Uninstalling prometheus-client-0.11.0:\n",
            "      Successfully uninstalled prometheus-client-0.11.0\n",
            "  Found existing installation: Cython 0.29.23\n",
            "    Uninstalling Cython-0.29.23:\n",
            "      Successfully uninstalled Cython-0.29.23\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-3.4.7 dawg-python-0.7.2 deeppavlov-0.15.0 fastapi-0.47.1 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-5.1.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 12:07:39.403 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_zh_bert_zh' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_zh_bert_zh.json'\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-sxrk3d27\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-sxrk3d27\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp37-none-any.whl size=23593 sha256=b6e9222b5eae04790d05cb13117e2c99dc1c7f69a883b476635e07e0ce2b377f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0mirwuc2/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n",
            "Requirement already satisfied: jieba==0.42.1 in /usr/local/lib/python3.7/dist-packages (0.42.1)\n",
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/81/84fb7a323f9723f81edfc796d89e89aa95a9446ed7353c144195b3a3a3ba/tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 62kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.2MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=351aa9bada2cc86564cbfacd41e47dc79a4077036a5133346f54faaa41d99d8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVDi4q656u9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55440180-aeb7-43c9-e8e7-0eaa85367c69"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "context = \"\"\"In 1888, The Football League was founded in England, becoming the first of many professional football competitions. During the 20th century, several of the various kinds of football grew to become some of the most popular team sports in the world.\"\"\"\n",
        "question = \"\"\"In which year the Football league was founded?\"\"\"\n",
        "\n",
        "model = build_model(configs.squad.squad_bert, download=True)\n",
        "result = model([context], [question])\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 12:08:42.98 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz to /root/.deeppavlov/squad_bert.tar.gz\n",
            "100%|██████████| 402M/402M [03:00<00:00, 2.23MB/s]\n",
            "2021-07-01 12:11:43.856 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/squad_bert.tar.gz archive into /root/.deeppavlov/models\n",
            "2021-07-01 12:11:49.377 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip\n",
            "100%|██████████| 404M/404M [01:23<00:00, 4.83MB/s]\n",
            "2021-07-01 12:13:14.294 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:81: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:178: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:154: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:166: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:89: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:94: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 12:13:38.535 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/squad_bert/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/squad_bert/model\n",
            "[['1888'], [3], [1744517.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MiE4Zf3-bQv"
      },
      "source": [
        "# 2) Open_Domain_QA_system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdfseJyR-lZf"
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.commands.infer import build_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9NTQtZY_JaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6dcdf2-8b4e-4109-d9bb-1141457f9d87"
      },
      "source": [
        "questions = [\"Where did guinea pigs originate?\", \"Who is virat kohli?\"]\n",
        "\n",
        "odqa = build_model(configs.odqa.en_odqa_infer_wiki, download = True)\n",
        "results = odqa(questions)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 12:13:43.954 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/multi_squad_model_noans_1.1.tar.gz to /root/.deeppavlov/multi_squad_model_noans_1.1.tar.gz\n",
            "100%|██████████| 265M/265M [00:50<00:00, 5.20MB/s]\n",
            "2021-07-01 12:14:36.240 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/multi_squad_model_noans_1.1.tar.gz archive into /root/.deeppavlov/models\n",
            "2021-07-01 12:14:42.946 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/en_odqa.tar.gz to /root/.deeppavlov/en_odqa.tar.gz\n",
            " 13%|█▎        | 629M/4.69G [01:28<11:12, 6.05MB/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljuCW6JH_nam"
      },
      "source": [
        "! ls root -a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL_mUgTO-lXP"
      },
      "source": [
        "print('hi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w7sU0LDsQbQ"
      },
      "source": [
        "# 3) Named_Entity_Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdVqzhNX-lVK"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SremAzFsfCJ",
        "outputId": "2f705bfd-51b7-4ee8-d88f-d008a9f001b9"
      },
      "source": [
        "model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)\n",
        "\n",
        "test_input = ['In 1888, The Football League was founded in England, becoming the first of many professional football competitions. During the 20th century, several of the various kinds of football grew to become some of the most popular team sports in the world.']\n",
        "results = model(test_input)\n",
        "# print(results[0][0])\n",
        "# print(results[1][0])\n",
        "results = pd.DataFrame(zip(results[0][0],results[1][0]), columns=['Word','Entity'])\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-28 17:58:45.413 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2021-06-28 17:59:24.185 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_mult_v1.tar.gz download because of matching hashes\n",
            "2021-06-28 17:59:24.516 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n",
            "2021-06-28 17:59:49.66 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model\n",
            "['In', '1888', ',', 'The', 'Football', 'League', 'was', 'founded', 'in', 'England', ',', 'becoming', 'the', 'first', 'of', 'many', 'professional', 'football', 'competitions', '.', 'During', 'the', '20th', 'century', ',', 'several', 'of', 'the', 'various', 'kinds', 'of', 'football', 'grew', 'to', 'become', 'some', 'of', 'the', 'most', 'popular', 'team', 'sports', 'in', 'the', 'world', '.']\n",
            "['O', 'B-DATE', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "            Word     Entity\n",
            "0             In          O\n",
            "1           1888     B-DATE\n",
            "2              ,          O\n",
            "3            The      B-ORG\n",
            "4       Football      I-ORG\n",
            "5         League      I-ORG\n",
            "6            was          O\n",
            "7        founded          O\n",
            "8             in          O\n",
            "9        England      B-GPE\n",
            "10             ,          O\n",
            "11      becoming          O\n",
            "12           the          O\n",
            "13         first  B-ORDINAL\n",
            "14            of          O\n",
            "15          many          O\n",
            "16  professional          O\n",
            "17      football          O\n",
            "18  competitions          O\n",
            "19             .          O\n",
            "20        During          O\n",
            "21           the     B-DATE\n",
            "22          20th     I-DATE\n",
            "23       century     I-DATE\n",
            "24             ,          O\n",
            "25       several          O\n",
            "26            of          O\n",
            "27           the          O\n",
            "28       various          O\n",
            "29         kinds          O\n",
            "30            of          O\n",
            "31      football          O\n",
            "32          grew          O\n",
            "33            to          O\n",
            "34        become          O\n",
            "35          some          O\n",
            "36            of          O\n",
            "37           the          O\n",
            "38          most          O\n",
            "39       popular          O\n",
            "40          team          O\n",
            "41        sports          O\n",
            "42            in          O\n",
            "43           the          O\n",
            "44         world          O\n",
            "45             .          O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2F5rF_gv3Qc"
      },
      "source": [
        "# 4) Sentiment_Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkYkVqeh-lQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21175991-7339-49a7-a969-35b849be6cbc"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "sentiment_model = build_model(configs.classifiers.insults_kaggle_bert, download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-29 14:20:35.655 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/datasets/insults_data.tar.gz download because of matching hashes\n",
            "2021-06-29 14:21:00.346 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/insults_kaggle_v3.tar.gz download because of matching hashes\n",
            "2021-06-29 14:21:02.111 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2021-06-29 14:21:02.200 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/classes.dict]\n",
            "2021-06-29 14:21:19.238 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK1kyqUNEx4D",
        "outputId": "417d8490-cfd4-4974-924c-80cc2c9571ea"
      },
      "source": [
        "test_input = ['This movie is good.', 'shame on you', 'go fuck yourself', 'you have done a great job']\n",
        "results = sentiment_model(test_input)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Not Insult', 'Not Insult', 'Insult', 'Not Insult']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "patxcqZ-L7Wn"
      },
      "source": [
        "# 5) Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_ORf0yrMEXI"
      },
      "source": [
        "# !pip install ktrain\n",
        "!pip install tensorflow == 2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Z7uyJAsN--",
        "outputId": "af5762ca-ca1f-4468-9f3e-de0ffeadf1b4"
      },
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "pprint(list(newsgroups_train.target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism',\n",
            " 'comp.graphics',\n",
            " 'comp.os.ms-windows.misc',\n",
            " 'comp.sys.ibm.pc.hardware',\n",
            " 'comp.sys.mac.hardware',\n",
            " 'comp.windows.x',\n",
            " 'misc.forsale',\n",
            " 'rec.autos',\n",
            " 'rec.motorcycles',\n",
            " 'rec.sport.baseball',\n",
            " 'rec.sport.hockey',\n",
            " 'sci.crypt',\n",
            " 'sci.electronics',\n",
            " 'sci.med',\n",
            " 'sci.space',\n",
            " 'soc.religion.christian',\n",
            " 'talk.politics.guns',\n",
            " 'talk.politics.mideast',\n",
            " 'talk.politics.misc',\n",
            " 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn_2ZMRX-lMO"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "\n",
        "def preprocess_dataset():\n",
        "    classes = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
        "    train_data = fetch_20newsgroups(subset='train', categories=classes, shuffle=True, random_state=42)\n",
        "    test_data = fetch_20newsgroups(subset='test', categories=classes, shuffle=True, random_state=42)    \n",
        "    return train_data.data,train_data.target, test_data.data, test_data.target, train_data.target_names\n",
        "\n",
        "def create_text_classification_model():\n",
        "    MODEL_NAME = 'distilbert-base-uncased'\n",
        "    train_features, train_labels, test_features, test_labels, train_classes = preprocess_dataset()\n",
        "    trans = text.Transformer(MODEL_NAME, maxlen=500, classes=train_classes)\n",
        "    train_preprocess = trans.preprocess_train(train_features, train_labels)\n",
        "    val_preprocess = trans.preprocess_test(test_features, test_labels)\n",
        "    model_data = trans.get_classifier()\n",
        "    classification_model = ktrain.get_learner(model_data, train_data=train_preprocess, val_data=val_preprocess, batch_size=6)\n",
        "    classification_model.fit_onecycle(5e-5, 4)\n",
        "    return classification_model, trans\n",
        "\n",
        "def predict_category(classification_model, trans, input_text):\n",
        "    predictor = ktrain.get_predictor(classification_model.model, preproc=trans)\n",
        "    predictor.save('my_predictor')\n",
        "    results = predictor.predict(input_text)\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu8e7OOC-lJv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "e28e5e8f-59df-4062-c8af-104f6f3d5033"
      },
      "source": [
        "classification_model, trans = create_text_classification_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ktrain/text/preprocessor.py:420: UserWarning: The class_names argument is replacing the classes argument. Please update your code.\n",
            "  warnings.warn('The class_names argument is replacing the classes argument. Please update your code.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 308\n",
            "\t95percentile : 837\n",
            "\t99percentile : 1938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 343\n",
            "\t95percentile : 979\n",
            "\t99percentile : 2562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Epoch 1/4\n",
            "377/377 [==============================] - 230s 591ms/step - loss: 0.5821 - accuracy: 0.8206 - val_loss: 0.3267 - val_accuracy: 0.8961\n",
            "Epoch 2/4\n",
            "377/377 [==============================] - 222s 588ms/step - loss: 0.1289 - accuracy: 0.9628 - val_loss: 0.2390 - val_accuracy: 0.9308\n",
            "Epoch 3/4\n",
            "377/377 [==============================] - 222s 589ms/step - loss: 0.0689 - accuracy: 0.9805 - val_loss: 0.2260 - val_accuracy: 0.9354\n",
            "Epoch 4/4\n",
            "377/377 [==============================] - 222s 589ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.1886 - val_accuracy: 0.9547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl1vVZtHmTQx",
        "outputId": "886cd56e-bad7-4288-a7dd-3643ae2ce58d"
      },
      "source": [
        "input_text = 'my platelets are decreasing.'\n",
        "print(predict_category(classification_model, trans, input_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sci.med\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM9ivvH9xdJ6",
        "outputId": "987a9726-1404-4952-b5ea-0dfe6ee58052"
      },
      "source": [
        "input_text = 'there is no god.'\n",
        "print(predict_category(classification_model, trans, input_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "soc.religion.christian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lodsiki6qUJf",
        "outputId": "356e0f36-1f0e-4c1c-857f-84d6a05a39bf"
      },
      "source": [
        "input_text = 'my brother is a graphics designer.'\n",
        "print(predict_category(classification_model, trans, input_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comp.graphics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azYc2R42-lHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fb0535-5bee-43fb-d9a4-7e4fb978c096"
      },
      "source": [
        "input_text = 'dont believe in god'\n",
        "print(predict_category(classification_model, trans, input_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alt.atheism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdkl9C9DyMro"
      },
      "source": [
        "# 6) Text_Summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpLbZWAhy8xO"
      },
      "source": [
        "!pip install summarizer\n",
        "!pip install torch+cpu torchvision+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install bert-extractive-summarizer\n",
        "!pip install git+https://github.com/dmmiller612/bert-extractive-summarizer.git@small-updates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkCqhu4qk-xh",
        "outputId": "4a073c88-8eb8-4976-ede2-6ed1364fa99d"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 31.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 37.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 28.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 31.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 32.7MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 30.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 28.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 30.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 31.3MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 31.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 31.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 31.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 31.3MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 31.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163kB 31.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 31.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 307kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0MB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 31.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DpzWPBpwBgz",
        "outputId": "62635723-1f3e-459a-b467-55263f51d8b4"
      },
      "source": [
        "!pip show summarizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: summarizer\n",
            "Version: 0.0.7\n",
            "Summary: A text summarizer\n",
            "Home-page: https://github.com/michigan-com/summarizer\n",
            "Author: Eric Bower\n",
            "Author-email: neurosnap@gmail.com\n",
            "License: The MIT License (MIT)\n",
            "        =====================        \n",
            "        Copyright (c) 2015 Michigan.com        \n",
            "        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "        of this software and associated documentation files (the \"Software\"), to deal\n",
            "        in the Software without restriction, including without limitation the rights\n",
            "        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "        copies of the Software, and to permit persons to whom the Software is\n",
            "        furnished to do so, subject to the following conditions:        \n",
            "        The above copyright notice and this permission notice shall be included in all\n",
            "        copies or substantial portions of the Software.        \n",
            "        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "        SOFTWARE.        \n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: nltk\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuqozGfxwPF"
      },
      "source": [
        "!pip install transformers==3.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBf24_mtyNd1",
        "outputId": "7ce67379-daf4-4261-aa95-418ad64d3122"
      },
      "source": [
        "import torch\n",
        "from summarizer import Summarizer\n",
        "\n",
        "\n",
        "text = \"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as 'training data', in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks.\"\n",
        " \n",
        "model=Summarizer()\n",
        "print(model(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Machine learning (ML) is the study of computer algorithms that improve automatically through experience.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jebG4VJ6yM_Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Jh1gDH-lE_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYdjsKOa6kmH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}