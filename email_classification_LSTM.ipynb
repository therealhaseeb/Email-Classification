{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "email_classification_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therealhaseeb/Email-Classification/blob/main/email_classification_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdmDkLCEvvYT",
        "outputId": "53c80540-9ccf-4d1e-d5e0-265e139d26c1"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Dropout, LSTM, Bidirectional\n",
        "from keras import Model\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import email\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import metrics \n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models.word2vec import Word2Vec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "5sLIB00TN1SV",
        "outputId": "7bedc050-6161-4d83-9e09-5f64ace622d7"
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload() \n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c41cc42-57cc-4443-9657-5b012768ef84\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c41cc42-57cc-4443-9657-5b012768ef84\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5weBobPOS1D",
        "outputId": "f766a02d-3803-427a-ee35-5d84bb2e246a"
      },
      "source": [
        "!kaggle datasets download -d wcukierski/enron-email-dataset\n",
        "!unzip /content/enron-email-dataset.zip\n",
        "!rm /content/enron-email-dataset.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading enron-email-dataset.zip to /content\n",
            " 97% 346M/358M [00:02<00:00, 199MB/s]\n",
            "100% 358M/358M [00:02<00:00, 167MB/s]\n",
            "Archive:  /content/enron-email-dataset.zip\n",
            "  inflating: emails.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX2PLjcXNbog"
      },
      "source": [
        "dataset = pd.read_csv('/content/emails.csv', nrows=5000)\n",
        "dataset_sent_mails = dataset[dataset['file'].str.contains('sent')]\n",
        "dataset_sent_mails = dataset_sent_mails.assign(sender=dataset_sent_mails[\"file\"].map(lambda x: re.search(\"(.*)/.*sent\", x).group(1)).values)\n",
        "dataset_sent_mails.drop(\"file\", axis=1, inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HJPkB3UNcre"
      },
      "source": [
        "users = dataset_sent_mails[\"sender\"].value_counts().head(15).index.values # extract top 15 users\n",
        "mapping = {}\n",
        "for i, user in enumerate(users, start = 1):\n",
        "  mapping[user] = i\n",
        "sent_user_dataset = dataset_sent_mails[dataset_sent_mails.sender.isin(users)] # extracted data of 15 users"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "vyiuEnmeOlZu",
        "outputId": "b03ed91d-1f54-4bbb-b3c4-35fc0cea4b20"
      },
      "source": [
        "sent_user_dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>sender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message   sender\n",
              "0  Message-ID: <18782981.1075855378110.JavaMail.e...  allen-p\n",
              "1  Message-ID: <15464986.1075855378456.JavaMail.e...  allen-p\n",
              "2  Message-ID: <24216240.1075855687451.JavaMail.e...  allen-p\n",
              "3  Message-ID: <13505866.1075863688222.JavaMail.e...  allen-p\n",
              "4  Message-ID: <30922949.1075863688243.JavaMail.e...  allen-p"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWHtWlF_qqXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2710cc04-942d-4bcc-f70e-a4c7d8bd93a6"
      },
      "source": [
        "sent_user_dataset.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2323, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGp-D3hQNdPt"
      },
      "source": [
        "# preprocessing email content\n",
        "def email_preprocessing(email_message):\n",
        "    msg = email.message_from_string(email_message)\n",
        "    \n",
        "    email_content = []\n",
        "    for part in msg.walk():\n",
        "        if part.get_content_type() == 'text/plain':\n",
        "            email_content.append(part.get_payload())\n",
        "            \n",
        "    result = {}\n",
        "    for key in msg.keys(): \n",
        "        result[key] = msg[key]\n",
        "    result[\"content\"] = ''.join(email_content)\n",
        "    # msg[\"content\"] = ''.join(email_content)\n",
        "    return result\n",
        "\n",
        "#Function for preprocessing of text data\n",
        "def content_preprocessing(content):\n",
        "    content = re.sub(\"[^a-zA-Z]\",\" \", content)\n",
        "    words = content.lower().split()\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    words = [w for w in words if not w in stops]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5tyKxaBNefo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "87fb8543-fb88-400e-915b-bbbadad6ca62"
      },
      "source": [
        "final_data = pd.DataFrame(list(map(email_preprocessing, sent_user_dataset.message)))\n",
        "final_data = pd.DataFrame(list(map(content_preprocessing, final_data[['Subject', 'content']].apply(lambda x: ' '.join(x), axis=1))), columns = [\"content\"])\n",
        "final_data = final_data.assign(user_number= sent_user_dataset[\"sender\"].values)\n",
        "final_data = final_data.replace({'user_number': mapping})\n",
        "final_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>user_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>forecast</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>traveling business meeting takes fun trip espe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test test successful way go</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>randy send schedule salary level everyone sche...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hello let shoot tuesday</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  user_number\n",
              "0                                           forecast            1\n",
              "1  traveling business meeting takes fun trip espe...            1\n",
              "2                        test test successful way go            1\n",
              "3  randy send schedule salary level everyone sche...            1\n",
              "4                            hello let shoot tuesday            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noUg-3EROyyr"
      },
      "source": [
        "final_data.to_csv(\"preprocessed_Data.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD_hSRWFFlZL"
      },
      "source": [
        "emails_words = final_data.content.apply(lambda x: x.split())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LqTWEcpFzOk"
      },
      "source": [
        "model = Word2Vec(np.array(emails_words))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agayjmuw7Rd1"
      },
      "source": [
        "model.wv.save_word2vec_format('/content/model.bin')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G2zD03K7Rq1"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "filename = '/content/model.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVrWpsDnNeaJ"
      },
      "source": [
        "X = final_data.content.values\n",
        "y_data = final_data.user_number.values\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6FcnjylNeQM"
      },
      "source": [
        "#converting into one hot encoded vectors\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(y_data.reshape(-1, 1))\n",
        "y_data = encoder.transform(y_data.reshape(-1, 1)).toarray()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTbtVnY4NaaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c166a25-8a73-424b-d489-285c130fe18f"
      },
      "source": [
        "X_data = []\n",
        "max_vec_len = 100\n",
        "max_seq_len = 100\n",
        "max_seq_len, max_vec_len"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjJpk5-yNeEk"
      },
      "source": [
        "# Get feature vectors of the word2vec model\n",
        "for email in emails_words:\n",
        "  x_arr = []\n",
        "  for word in email[:max_seq_len]:\n",
        "    try:\n",
        "      x_arr.append(model[word])\n",
        "    except:\n",
        "      pass\n",
        "  if max_seq_len - len(x_arr) > 0:\n",
        "    for _ in range(max_seq_len - len(x_arr)):\n",
        "      x_arr.append(np.zeros(shape=(max_vec_len,)))\n",
        "  X_data.append(np.array(x_arr))\n",
        "  if len(X_data)%5000 == 0:\n",
        "    print(\"Next 500 batched finished\")\n",
        "X_data = np.array(X_data)\n",
        "\n",
        "# np.save('/content/word2vec_data', X_data)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ20EOetRGWo"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2) #spliting into training and testing"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxHapUBQ_VOU"
      },
      "source": [
        "# LSTM model containing encoder LSTM layers and fully connected layers.\n",
        "class LSTM_Model:\n",
        "    \n",
        "    def __init__(self, enc_seq_length, enc_unique_states, output_states, enc_layers=1, \n",
        "                 dense__prev_layers_neurons=[], lstm_units = 256, \n",
        "                 bidirectional=False, dropout=0, recurrent_dropout=0, bias_regularizer=None, \n",
        "                 kernel_regularizer=None, activity_regularizer=None):\n",
        "        self.enc_seq_length = enc_seq_length\n",
        "        self.enc_unique_states = enc_unique_states\n",
        "        self.enc_layers = enc_layers\n",
        "        self.output_states = output_states\n",
        "        self.dense__prev_layers_neurons = dense__prev_layers_neurons\n",
        "        self.lstm_units = lstm_units\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dropout = dropout\n",
        "        self.recurrent_dropout = recurrent_dropout\n",
        "        self.bias_regularizer = bias_regularizer\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.activity_regularizer = activity_regularizer\n",
        "        self.dense__prev_layers_neurons.append(self.output_states)\n",
        "        \n",
        "    def getModel(self):\n",
        "        \n",
        "        self.encoder_inputs = Input(shape=(None, self.enc_unique_states), name='encoder_inputs')\n",
        "        \n",
        "        self.encoder = []\n",
        "        self.encoder_outputs = []\n",
        "        \n",
        "        # Add encoder layers \n",
        "        for i in range(self.enc_layers-1):\n",
        "            self.encoder.append(LSTM(self.lstm_units, \n",
        "                                     return_sequences=True, \n",
        "                                     recurrent_dropout=self.recurrent_dropout, \n",
        "                                     dropout = self.dropout, \n",
        "                                     bias_regularizer = self.bias_regularizer, \n",
        "                                     activity_regularizer = self.activity_regularizer, \n",
        "                                     kernel_regularizer=self.kernel_regularizer, \n",
        "                                     name=\"encoder\"+str(i+1)))\n",
        "            # Wrap Bidirectional layer if bidirectional is True\n",
        "            if self.bidirectional:\n",
        "                self.encoder[i] = Bidirectional(self.encoder[i])\n",
        "            \n",
        "        self.encoder.append(LSTM(self.lstm_units,  \n",
        "                                 recurrent_dropout=self.recurrent_dropout, \n",
        "                                 dropout = self.dropout, \n",
        "                                 bias_regularizer = self.bias_regularizer, \n",
        "                                 activity_regularizer = self.activity_regularizer, \n",
        "                                 kernel_regularizer=self.kernel_regularizer, \n",
        "                                 name=\"encoder\"+str(self.enc_layers)))\n",
        "        if self.bidirectional:\n",
        "                self.encoder[self.enc_layers-1] = Bidirectional(self.encoder[self.enc_layers-1])\n",
        "        \n",
        "        # Get encoder outputs for each encoder layer\n",
        "        for i in range(self.enc_layers):\n",
        "            if i==0:\n",
        "                self.encoder_outputs.append(self.encoder[i]((self.encoder_inputs)))\n",
        "            else:\n",
        "                self.encoder_outputs.append(self.encoder[i](self.encoder_outputs[i-1]))\n",
        "        \n",
        "        self.decoder_dense = []\n",
        "        self.dense_outputs = []\n",
        "        self.dense_layers = len(self.dense__prev_layers_neurons)\n",
        "        \n",
        "        # Add fully connected layers\n",
        "        for i in range(self.dense_layers):\n",
        "            if i < self.dense_layers-1:\n",
        "                self.decoder_dense.append(Dense(self.dense__prev_layers_neurons[i], \n",
        "                                                bias_regularizer = self.bias_regularizer, \n",
        "                                                activity_regularizer = self.activity_regularizer, \n",
        "                                                activation='tanh', name=\"output_layer\"+str(i+1)))\n",
        "            else:\n",
        "                self.decoder_dense.append(Dense(self.dense__prev_layers_neurons[i], \n",
        "                                                bias_regularizer = self.bias_regularizer, \n",
        "                                                activity_regularizer = self.activity_regularizer, \n",
        "                                                activation='softmax', name=\"softmax\"))                \n",
        "            \n",
        "        # Get outputs of each fully connected layer\n",
        "        for i in range(self.dense_layers):\n",
        "            if i==0:\n",
        "                self.dense_outputs.append(self.decoder_dense[i](self.encoder_outputs[self.enc_layers-1]))\n",
        "            else:\n",
        "                self.dense_outputs.append(self.decoder_dense[i](self.dense_outputs[i-1]))\n",
        "        \n",
        "\n",
        "        self.model = Model(self.encoder_inputs, self.dense_outputs[self.dense_layers-1])\n",
        "        \n",
        "        return self.model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPhJmGAVBjwd"
      },
      "source": [
        "enc_seq_length = max_seq_len\n",
        "enc_unique_states = max_vec_len\n",
        "output_states = len(encoder.get_feature_names())\n",
        "model = LSTM_Model(enc_seq_length, \n",
        "              enc_unique_states,\n",
        "              output_states,\n",
        "              enc_layers=1,\n",
        "              lstm_units = 12,\n",
        "              dense__prev_layers_neurons=[24],\n",
        "              dropout = 0.1).getModel()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgREhoU40r1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069b2412-14f9-4b4d-b49e-fdc9c7732eac"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_inputs (InputLayer)  [(None, None, 100)]       0         \n",
            "_________________________________________________________________\n",
            "encoder1 (LSTM)              (None, 12)                5424      \n",
            "_________________________________________________________________\n",
            "output_layer1 (Dense)        (None, 24)                312       \n",
            "_________________________________________________________________\n",
            "softmax (Dense)              (None, 2)                 50        \n",
            "=================================================================\n",
            "Total params: 5,786\n",
            "Trainable params: 5,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbdFray0mSR5"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.002,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.5)\n",
        "\n",
        "my_optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unCS0gZscAZW"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REN2YGM0bw4a"
      },
      "source": [
        "checkpointer = keras.callbacks.ModelCheckpoint(\"/content/weights_e{epoch:02d}-vl{val_loss:.2f}.hdf5\", \n",
        "                                       monitor='accuracy',\n",
        "                                       verbose=1, \n",
        "                                       save_best_only=True, \n",
        "                                       mode='max')\n",
        "\n",
        "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=3)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRUjtF0r06vv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76229f7d-679a-4034-971b-ac8b669283eb"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=5,\n",
        "                    callbacks=[early_stopping_monitor, checkpointer],\n",
        "                    validation_split=0.3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 22s 45ms/step - loss: 0.6801 - accuracy: 0.6464 - val_loss: 0.6504 - val_accuracy: 0.6505\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.66154, saving model to /content/weights_e01-vl0.65.hdf5\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 0.6337 - accuracy: 0.6794 - val_loss: 0.6485 - val_accuracy: 0.6505\n",
            "\n",
            "Epoch 00002: accuracy did not improve from 0.66154\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.6413 - accuracy: 0.6593 - val_loss: 0.6473 - val_accuracy: 0.6505\n",
            "\n",
            "Epoch 00003: accuracy did not improve from 0.66154\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.6400 - accuracy: 0.6622 - val_loss: 0.6481 - val_accuracy: 0.6505\n",
            "\n",
            "Epoch 00004: accuracy did not improve from 0.66154\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.6488 - accuracy: 0.6497 - val_loss: 0.6472 - val_accuracy: 0.6505\n",
            "\n",
            "Epoch 00005: accuracy did not improve from 0.66154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lokAiyMh6NO"
      },
      "source": [
        "model.save('lstm.h5')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjcfRWLAcQH3"
      },
      "source": [
        "preds = model.predict(X_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU_035fTia56",
        "outputId": "f061effb-379b-4a09-bfb9-2961849633ca"
      },
      "source": [
        "confusion_matrix(y_test.argmax(axis=1), preds.argmax(axis=1))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[286,   0],\n",
              "       [179,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtFcP15NRLWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd34bb9b-6fd9-4ddf-b79f-080668ad1f40"
      },
      "source": [
        "accuracy_score(y_test.argmax(axis=1), preds.argmax(axis=1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6150537634408603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5mnVnYBsbTh"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}